{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-running-cool-roof-process\n",
    "Rachel Bowers, Analayst II at Metropolitan Area Planning Council\n",
    "\n",
    "\n",
    "This notebook runs scripts to process Lidar point cloud data, roofprint data, and assessors data from MassGIS, resulting in building footprints for all of Metro Mayors region with added fields for:\n",
    "- Whether the average pitch of the roof indicates that it is a \"low slope\" roof suitable for cool roof conversion\n",
    "- The relative reflectivity over the roofprint area\n",
    "- Additional land use and socio-environmental variables that indicate whether cool roof conversions may be particularly impactful or appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in scripts  \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.features.create_rasters import *#\n",
    "#from src.features.arcpy_scripts import *\n",
    "from src.features.custom_functions import * \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run these only when new lidar or to re-run heat_score_mmc\n",
    "\n",
    "- las_dataset was last created for all MMC on 5/1/2024\n",
    "- heat_score_mmc was last created for all MMC on 5/1/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only run this if need be [last run on all MMC: 5/1/2024]\n",
    "from src.data.make_dataset import heat_fp, las_folder\n",
    "\n",
    "#dataset file path\n",
    "las_dataset = r'I:\\Imagery\\MassGIS_LAS_files\\MMC_lasdataset.lasd'\n",
    "\n",
    "las_dataset = create_las_dataset(las_folder=las_folder, las_dataset=las_dataset)\n",
    "\n",
    "heat_score_mmc = get_heat_score_mmc(heat_index_fp=heat_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First create slope and intensity rasters for each municipality\n",
    "\n",
    "Result in geodatabase should be just a slope and intensity raster for each muni - note, as of 5/22, this can be skipped (unless you need to rerun any of them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmc_town_names = ['Arlington', 'Boston', 'Braintree', 'Brookline', 'Cambridge', 'Chelsea', \n",
    "             'Everett', 'Malden', 'Medford', 'Melrose', 'Newton', 'Quincy', 'Revere', \n",
    "             'Somerville', 'Watertown', 'Winthrop']\n",
    "\n",
    "\n",
    "#note that Revere was removed from this list since it was the test one \n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "for town_name in mmc_town_names:\n",
    "    \n",
    "    print(town_name + ' processing starting at ' + str(datetime.now()))\n",
    "\n",
    "\n",
    "    #create las dataset \n",
    "    las_dataset = create_las_dataset(town_name = town_name, \n",
    "                                     las_folder=las_folder) \n",
    "    \n",
    "    #create an ndsm raster\n",
    "    ndsm_raster = create_ndsm_raster(town_name=town_name,\n",
    "                                    las_dataset=las_dataset)\n",
    "    \n",
    "    #create a slope raster that covers each roofprint\n",
    "    slope_raster = create_slope_raster(town_name=town_name,\n",
    "                                        ndsm_raster=ndsm_raster)\n",
    "    \n",
    "    #removing aspect for now, may include later to refine the flat roof analysis\n",
    "    #aspect_raster = create_aspect_raster(town_name=town_name,\n",
    "    #                                     ndsm_raster=ndsm_raster)\n",
    "\n",
    "    #create an intensity raster that covers each roofprint\n",
    "    intensity_raster = create_intensity_raster(town_name=town_name, \n",
    "                                                las_dataset=las_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then create enriched roofprint polygon datasets\n",
    "\n",
    "Enriches roofprint data with land use and socio-enviro fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.make_dataset import mmc_heat_blocks\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "mmc_town_names = ['Arlington', 'Boston', 'Braintree', 'Brookline', 'Cambridge', 'Chelsea', \n",
    "             'Everett', 'Malden', 'Medford', 'Melrose', 'Newton', 'Quincy', 'Revere', \n",
    "             'Somerville', 'Watertown', 'Winthrop']\n",
    "\n",
    "for town_name in mmc_town_names:\n",
    "  \n",
    "    data_folder = r'K:\\DataServices\\Projects\\Current_Projects\\Climate_Change\\MVP_MMC_CoolRoofs_MVP\\Data\\Intermediate'\n",
    "    cool_roof_footprints_layer = os.path.join(data_folder, (town_name + '_cool_roofs.shp'))\n",
    "    \n",
    "    if arcpy.Exists(cool_roof_footprints_layer): #an existing out_slope_raster would mean this town has already been processed\n",
    "        print('cool roofs have been processed for ' + town_name + '. Moving to next town.')\n",
    "        pass\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(town_name + ' processing starting at ' + str(datetime.now()))\n",
    "    \n",
    "        rooftops_layer = make_coolroof_roofprints_layer(town_name=town_name)\n",
    "        \n",
    "        #input for the cool_roof_process() function has to be a gdf\n",
    "        rooftops_gdf = gpd.read_file(cool_roofs_gdb, layer=(town_name + '_footprints'))\n",
    "\n",
    "        town_structures_w_info = cool_roof_process(town_name=town_name, \n",
    "                                                    rooftops_layer=rooftops_gdf,\n",
    "                                                    heat_blocks_layer=mmc_heat_blocks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging\n",
    "\n",
    "To rerun the cool roof processing (rather than the development of the baseline footprint layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rerunning just the cool_roof_process() part\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from src.data.make_dataset import mmc_heat_blocks\n",
    "\n",
    "mmc_town_names = ['Arlington', 'Boston', 'Braintree', 'Brookline', 'Cambridge', 'Chelsea', \n",
    "                'Everett', 'Malden', 'Medford', 'Melrose', 'Newton', 'Quincy', 'Revere', \n",
    "                'Somerville', 'Watertown', 'Winthrop']\n",
    "\n",
    "for town_name in mmc_town_names:\n",
    "    print(town_name, ' starting at ', datetime.now())\n",
    "\n",
    "    rooftops_gdf = gpd.read_file(cool_roofs_gdb, layer=(town_name + '_footprints'))\n",
    "\n",
    "    town_structures_w_info = cool_roof_process(town_name=town_name, \n",
    "                                                rooftops_layer=rooftops_gdf,\n",
    "                                                heat_blocks_layer=mmc_heat_blocks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge shapefiles together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MERGE SHAPEFILES ##\n",
    "\n",
    "from src.data.make_dataset import input_dir, intermediate_path, output_dir\n",
    "\n",
    "filelist = []\n",
    "\n",
    "# add all shapefiles\n",
    "for root, folder, files in os.walk(intermediate_path):\n",
    "    for file in files:\n",
    "        for muni in mmc_town_names:\n",
    "            if muni in file:\n",
    "                if file.endswith('.shp'):\n",
    "                    fullname = os.path.join(root, file)\n",
    "                    filelist.append(fullname)\n",
    "\n",
    "merged_gdf = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in filelist], \n",
    "                        ignore_index=True), crs=gpd.read_file(filelist[0]).crs)\n",
    "\n",
    "#export\n",
    "output_path = os.path.join(output_dir, 'MMC_Cool_Roofs.shp')\n",
    "merged_gdf.to_file(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional debugging: Replace any towns as needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace with any towns you want to rerun analysis on\n",
    "munis_to_fix = ['Watertown']\n",
    "\n",
    "## RUN ANALYSIS ON MUNIS OF CHOICE ## \n",
    "\n",
    "from src.data.make_dataset import intermediate_path, output_dir\n",
    "\n",
    "\n",
    "# make cool roof roofprints, add socio-enviro fields\n",
    "\n",
    "for town_name in munis_to_fix:\n",
    "    print('rerunning analysis on ' + town_name)\n",
    "\n",
    "    rooftops_layer = make_coolroof_roofprints_layer(town_name=town_name)\n",
    "    \n",
    "    # input for the cool_roof_process() function has to be a gdf\n",
    "    rooftops_gdf = gpd.read_file(cool_roofs_gdb, layer=(town_name + '_footprints'))\n",
    "\n",
    "    town_structures_w_info = cool_roof_process(town_name=town_name, \n",
    "                                                rooftops_layer=rooftops_gdf,\n",
    "                                                heat_blocks_layer=mmc_heat_blocks)\n",
    "\n",
    "\n",
    "# output of the above is a shapefile to be read back in\n",
    "\n",
    "for root, folder, files in os.walk(intermediate_path):\n",
    "    for file in files:\n",
    "        for town_name in munis_to_fix:\n",
    "            if town_name in file:\n",
    "                if file.endswith('.shp'):\n",
    "                    fullname = os.path.join(root, file)\n",
    "                    filelist.append(fullname)\n",
    "\n",
    "\n",
    "fixed_munis_gdf = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in filelist], \n",
    "                        ignore_index=True), crs=gpd.read_file(filelist[0]).crs)\n",
    "\n",
    "\n",
    "# read in existing gdf of all MMC munis \n",
    "print('reading in existing dataset')\n",
    "output_path = os.path.join(output_dir, 'MMC_Cool_Roofs.shp')\n",
    "existing_gdf = gpd.read_file(output_path)\n",
    "\n",
    "# create new gdf that excludes the existing rows from the munis of interest\n",
    "existing_gdf_minus_munis = existing_gdf.loc[~existing_gdf.CITY.isin(munis_to_fix)]\n",
    "\n",
    "# add the gdf with fixed munis\n",
    "fixed_gdf = pd.concat([existing_gdf_minus_munis, fixed_munis_gdf])\n",
    "print('exporting final dataset')\n",
    "fixed_gdf.to_file(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
